{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinweeee/NLP_Projects/blob/main/NLP_Projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project: Write a program that scans a document and extracts all the email addresses. You can use rule-based matching to identify patterns that match the structure of an email address."
      ],
      "metadata": {
        "id": "BHSfSCncVurB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "xWlN4XNlVxPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "email_matcher = Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "rY_sNC9oXEi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hello John, I hope this email finds you well. We're excited to announce that our new product will be launching next week. For more details, please reach out to our product manager at product.manager@example.com. Also, our marketing team is planning a promotional event. If you're interested in participating, please contact our event coordinator at events.coordinator@example.com. Lastly, if you have any general inquiries, feel free to reach out to our customer service at customer.service@example.com. Best, Jane Doe jane.doe@example.com\")"
      ],
      "metadata": {
        "id": "lOwd0I_LaCtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_1 = [{'LIKE_EMAIL': True}]\n",
        "\n",
        "email_matcher.add('Email Address', [pattern_1])\n",
        "find_matches = email_matcher(doc)\n",
        "print(find_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8qKpTn_XS2h",
        "outputId": "7d14da57-350b-4045-df8d-b4fe870a6d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(17145694160672783604, 38, 39), (17145694160672783604, 64, 65), (17145694160672783604, 85, 86), (17145694160672783604, 91, 92)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for hash_id, start, end in find_matches:\n",
        "  string_id = nlp.vocab.strings[hash_id]\n",
        "  span = doc[start:end]\n",
        "  print(hash_id, string_id, start,end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7CT2O3aYKr0",
        "outputId": "cbb81fa2-9496-4820-db03-ca0dc1aece2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17145694160672783604 Email Address 38 39 product.manager@example.com\n",
            "17145694160672783604 Email Address 64 65 events.coordinator@example.com\n",
            "17145694160672783604 Email Address 85 86 customer.service@example.com\n",
            "17145694160672783604 Email Address 91 92 jane.doe@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALTERNATIVELY"
      ],
      "metadata": {
        "id": "k44azz1tcECv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "email_matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"Hello John, I hope this email finds you well. We're excited to announce that our new product will be launching next week. For more details, please reach out to our product manager at product.manager@example.com. Also, our marketing team is planning a promotional event. If you're interested in participating, please contact our event coordinator at events.coordinator@example.com. Lastly, if you have any general inquiries, feel free to reach out to our customer service at customer.service@example.com. Best, Jane Doe jane.doe@example.com\")\n",
        "\n",
        "pattern = [{\"TEXT\": {\"REGEX\": r\"[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+\"}}]\n",
        "\n",
        "email_matcher.add('Email Address', [pattern])\n",
        "find_matches = email_matcher(doc)\n",
        "print(find_matches)\n",
        "\n",
        "for hash_id, start, end in find_matches:\n",
        "  string_id = nlp.vocab.strings[hash_id]\n",
        "  span = doc[start:end]\n",
        "  print(hash_id, string_id, start,end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJEdtwwpbTH4",
        "outputId": "0b54c2b8-8e12-4108-d9ee-c8a8958aa886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(17145694160672783604, 38, 39), (17145694160672783604, 64, 65), (17145694160672783604, 85, 86), (17145694160672783604, 91, 92)]\n",
            "17145694160672783604 Email Address 38 39 product.manager@example.com\n",
            "17145694160672783604 Email Address 64 65 events.coordinator@example.com\n",
            "17145694160672783604 Email Address 85 86 customer.service@example.com\n",
            "17145694160672783604 Email Address 91 92 jane.doe@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date Finder:** Create a program that can find and extract all dates from a document. Dates can come in various formats (e.g., MM-DD-YYYY, DD/MM/YYYY, Month Day, Year, etc.), so you'll need to create different rules to match each format."
      ],
      "metadata": {
        "id": "_Nw8E10LRUw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_matcher = Matcher(nlp.vocab)\n",
        "\n",
        "date_text = nlp(\"John's birthday is on 12/25/1990. He started his first job on June 15, 2010. His last day at that job was 2015-07-31. He then took a year off, so he didn't start his new job until 08/01/2016. He has a meeting scheduled for March 1, 2022. His project deadline is 05-15-2022.\")\n",
        "\n",
        "# MM/DD/YYYY\n",
        "pattern_date1 = [{'LIKE_NUM': True}, {'ORTH': '/'}, {'LIKE_NUM': True}, {'ORTH': '/'}, {'LIKE_NUM': True}]\n",
        "# MM-DD-YYYY\n",
        "pattern_date2 = [{'LIKE_NUM': True}, {'ORTH': '-'}, {'LIKE_NUM': True}, {'ORTH': '-'}, {'LIKE_NUM': True}]\n",
        "# dates of the form 10-Aug-2018\n",
        "pattern_date3 = [{'SHAPE': 'dd'}, {'ORTH': '-'}, {'IS_ALPHA': True}, {'ORTH': '-'}, {'SHAPE': 'dddd'}]\n",
        "# dates of the form Aug-10-2018\n",
        "pattern_date4 = [{'IS_ALPHA': True}, {'ORTH': '-'}, {'SHAPE': 'dd'}, {'ORTH': '-'}, {'SHAPE': 'dddd'}]\n",
        "# dates of the form Month DD, YYYY\n",
        "pattern_date5 = [{'IS_ALPHA': True}, {'IS_SPACE': True, 'OP':'?'}, {'LIKE_NUM': True}, {'ORTH': ','}, {'LIKE_NUM': True}]\n",
        "# dates of the form 10 August 2018\n",
        "pattern_date6 = [{'SHAPE': 'dd'}, {'IS_ALPHA': True}, {'SHAPE': 'dddd'}]\n",
        "# YYYY/MM/DD\n",
        "pattern_date7 = [{'SHAPE': 'dddd'}, {'ORTH': '/'}, {'SHAPE': 'dd'}, {'ORTH': '/'}, {'SHAPE': 'dd'}]\n",
        "# YYYY-MM-DD\n",
        "pattern_date8 = [{'SHAPE': 'dddd'}, {'ORTH': '-'}, {'SHAPE': 'dd'}, {'ORTH': '-'}, {'SHAPE': 'dd'}]\n",
        "\n",
        "\n",
        "\n",
        "date_matcher.add(\"MM/DD/YYYY\", [pattern_date1])\n",
        "date_matcher.add(\"MM-DD-YYYY\", [pattern_date2])\n",
        "date_matcher.add(\"10-Aug-2018\", [pattern_date3])\n",
        "date_matcher.add(\"Aug-10-2018\", [pattern_date4])\n",
        "date_matcher.add(\"Month DD, YYYY\", [pattern_date5])\n",
        "date_matcher.add(\"10 August 2018\", [pattern_date6])\n",
        "date_matcher.add(\"YYYY/MM/DD\", [pattern_date7])\n",
        "date_matcher.add(\"YYYY-MM-DD\", [pattern_date8])\n",
        "\n",
        "find_date_matches = date_matcher(date_text)\n",
        "\n",
        "for match_id, start, end in find_date_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "    span = date_text[start:end]\n",
        "    print(f\"{string_id}: {span.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJnG28k3XhK3",
        "outputId": "552ff69f-f192-42c3-d49f-e293458cba3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Month DD, YYYY: June 15, 2010\n",
            "MM-DD-YYYY: 2015-07-31\n",
            "YYYY-MM-DD: 2015-07-31\n",
            "Month DD, YYYY: March 1, 2022\n",
            "MM-DD-YYYY: 05-15-2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hashtag Analyzer:** Analyze social media posts or comments for hashtags. Write a program that can extract all hashtags from a given text. This will help you understand how to create rules for specific patterns."
      ],
      "metadata": {
        "id": "gGoiSJ-Vbgzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hashtag_matcher = Matcher(nlp.vocab)\n",
        "\n",
        "hash_text = nlp('\"Excited to start my new journey at #Google! Looking forward to learning new things and meeting new people. #FirstDay #NaturalLanguageDev #CodingLife #TechIndustry\"')\n",
        "\n",
        "pattern = [{'ORTH': '#'}, {'IS_ASCII': True}]\n",
        "hashtag_matcher.add(\"Hashtag_text\", [pattern])\n",
        "\n",
        "find_hash_matches = hashtag_matcher(hash_text)\n",
        "\n",
        "for hash_id, start, end in find_hash_matches:\n",
        "    string_id = nlp.vocab.strings[hash_id]\n",
        "    span = hash_text[start:end]\n",
        "    print(hash_id, string_id, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ebdBVzhpiH",
        "outputId": "5f14f92a-1afe-48b6-cbf1-2c031df48045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7370499323740246234 Hashtag_text 8 10 #Google\n",
            "7370499323740246234 Hashtag_text 22 24 #FirstDay\n",
            "7370499323740246234 Hashtag_text 24 26 #NaturalLanguageDev\n",
            "7370499323740246234 Hashtag_text 26 28 #CodingLife\n",
            "7370499323740246234 Hashtag_text 28 30 #TechIndustry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**URL Extractor:** Write a program that can extract all URLs from a document. This will involve creating rules that match the structure of a URL.\n",
        "\n"
      ],
      "metadata": {
        "id": "qyhlz53rozuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_matcher = Matcher(nlp.vocab)\n",
        "\n",
        "\n",
        "url_text = nlp('\"Check out my blog at https://www.myblog.com for more info. You can also follow me on Twitter (https://twitter.com/myhandle) and LinkedIn (https://www.linkedin.com/in/myprofile). Here are some of my favorite resources: https://www.python.org, https://stackoverflow.com, and https://github.com.\"')\n",
        "pattern = [{'LIKE_URL': True}]\n",
        "\n",
        "\n",
        "url_matcher.add(\"URLs: \", [pattern])\n",
        "find_url_matches = url_matcher(url_text)\n",
        "\n",
        "for hash_id, start, end, in find_url_matches:\n",
        "    string_id = nlp.vocab.strings[hash_id]\n",
        "    span = url_text[start:end]\n",
        "    print(hash_id, string_id, start, end, span.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvqnEUwxiMes",
        "outputId": "b07a4169-6f3e-4eea-d990-43ee4b09b7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8221967826680415688 URLs:  6 7 https://www.myblog.com\n",
            "8221967826680415688 URLs:  19 20 https://twitter.com/myhandle\n",
            "8221967826680415688 URLs:  24 25 https://www.linkedin.com/in/myprofile\n",
            "8221967826680415688 URLs:  35 36 https://www.python.org\n",
            "8221967826680415688 URLs:  37 38 https://stackoverflow.com\n",
            "8221967826680415688 URLs:  40 41 https://github.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition:** While libraries like spaCy have built-in NER capabilities, you can try to build a simple NER system using rule-based matching. For example, you could write rules to identify person names, organizations, or locations."
      ],
      "metadata": {
        "id": "0BECbt8i2a6G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cui8TuYRKjWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_matcher = Matcher(nlp.vocab)\n",
        "\n",
        "ner_text = nlp(\"Google, led by CEO Sundar Pichai, is headquartered in Mountain View, California.\")\n",
        "\n",
        "ner_pattern =  [{\"LOWER\": \"google\"},  {\"LOWER\": \"by\"}, {\"LOWER\": \"ceo\"}, {},\n",
        "           {\"LOWER\": \"is\"}, {\"LOWER\": \"headquartered\"}, {\"LOWER\": \"in\"}, {}, {}]\n",
        "\n",
        "\n",
        "ner_matcher.add(\"Identified Tokens :\", [ner_pattern])\n",
        "find_ner_matches = ner_matcher(ner_text)\n",
        "\n",
        "for hash_id, start, end in find_ner_matches:\n",
        "  string_id = nlp.vocab.strings[hash_id]\n",
        "  span = ner_text[start:end]\n",
        "  print(hash_id, string_id, start, end, span.text)"
      ],
      "metadata": {
        "id": "ERMdvjbMqn4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "text = \"Google, led by CEO Sundar Pichai, is headquartered in Mountain View, California.\"\n",
        "\n",
        "doc_ner = nlp(text)\n",
        "displacy.render(doc_ner, style='ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "pRBB2-aeJk3f",
        "outputId": "deb7041a-5ece-4210-ff9d-2c0a396bcd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", led by CEO \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sundar Pichai\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", is headquartered in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mountain View\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    California\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}